{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a4711de",
   "metadata": {},
   "source": [
    "<div  style=\"background-color:white;\"><h1 style=\"text-align:center; color:purple;\">D√©tection de sentiments avec un RNN\n",
    "</h1>\n",
    "\n",
    "<p style=\"text-align:center; color:black\"><strong>Pr√©par√©  Par :</strong> Hafsa Zian | <strong>Fili√®re :</strong> Machine Learning & IA | <strong>Encadr√© Par :</strong> M. Harchli Fidae</p>\n",
    "\n",
    "<hr></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3d8507",
   "metadata": {},
   "source": [
    "<center><h2> üìö Sommaire<h2> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938b8c18",
   "metadata": {},
   "source": [
    "1. <a href=\"#intro\">Introduction</a><br>\n",
    "\n",
    "2. <a href=\"#import\">Importation des biblioth√®ques n√©cessaires</a><br>\n",
    "\n",
    "3. <a href=\"#donnees\">Donn√©es d'apprentissage</a><br>\n",
    "\n",
    "4. <a href=\"#pretraitement\">Pr√©traitement des donn√©es</a><br>\n",
    "‚ÄÉa. <a href=\"#tokenisation\">Tokenisation</a><br>\n",
    "‚ÄÉb. <a href=\"#vocabulaire\">Cr√©ation du vocabulaire</a><br>\n",
    "‚ÄÉc. <a href=\"#remp\">Remplacement chaque mot par son indice dans ce vocabulaire</a><br>\n",
    "‚ÄÉd. <a href=\"#raison\">Raison d'ajout un jeton pad</a><br>\n",
    "\n",
    "5. <a href=\"#encodage\">Encodage</a><br> \n",
    "    a. <a href=\"#encode\">Encodez chaque phrase sous forme de s√©quence d‚Äôindices </a><br>\n",
    "    b. <a href=\"#padding\"> Padding sur les s√©quences </a><br>\n",
    "\n",
    "6. <a href=\"#modele\">Construction du mod√®le RNN</a><br>\n",
    "\n",
    "7. <a href=\"#entrainement\">Entra√Ænement du mod√®le</a><br>\n",
    "\n",
    "8. <a href=\"#prediction\">Pr√©diction</a><br>\n",
    "\n",
    "9. <a href=\"#qst\">r√©ponses aux questions th√©oriques</a><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751ec16f",
   "metadata": {},
   "source": [
    "### üìå 1. Introduction <span id=\"intro\"></span>\n",
    "\n",
    "Dans ce travail pratique, nous allons impl√©menter un mod√®le de R√©seau de Neurones R√©current (RNN) pour la d√©tection de sentiments √† partir de phrases textuelles. L'objectif est de classer chaque phrase comme exprimant un sentiment positif (√©tiquette 1) ou n√©gatif (√©tiquette 0), en se basant sur le contenu des mots et leur ordre.\n",
    "\n",
    "\n",
    "#### üéØ Objectif \n",
    "\n",
    "Construire, entra√Æner et tester un mod√®le RNN capable de comprendre et de g√©n√©raliser les relations entre les mots d'une phrase et le sentiment qu'elle exprime, en utilisant un petit jeu de donn√©es √©tiquet√©.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7ee564",
   "metadata": {},
   "source": [
    "### üß∞ 2. Importation des biblioth√®ques n√©cessaires <span id=\"import\"></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9678f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  # Pour le nettoyage des phrases (tokenisation simple)\n",
    "from collections import Counter  # Pour compter les mots\n",
    "import torch  # PyTorch pour le mod√®le et les tenseurs\n",
    "import torch.nn as nn  # Pour les couches du r√©seau de neurones\n",
    "from keras.preprocessing.sequence import pad_sequences  # Pour le padding des s√©quences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd8efe6",
   "metadata": {},
   "source": [
    "### üìä 3. Donn√©es d'apprentissage <span id=\"donnees\"></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62dede91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phrases d'entra√Ænement\n",
    "phrases = [\n",
    "    \"Je suis tr√®s content\",\n",
    "    \"C'√©tait une belle journ√©e\",\n",
    "    \"Je suis d√©√ßu\",\n",
    "    \"C'√©tait horrible\",\n",
    "    \"J'adore ce film\",\n",
    "    \"Je d√©teste ce livre\"\n",
    "]\n",
    "\n",
    "# Labels correspondants (1 = positif, 0 = n√©gatif)\n",
    "labels = [1, 1, 0, 0, 1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d3494b",
   "metadata": {},
   "source": [
    "### üßπ 4. Pr√©traitement des donn√©es <span id=\"pretraitement\"></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d0931e",
   "metadata": {},
   "source": [
    "#### a. Tokenisation  <span id=\"tokenisation\"></span>‚ÄÉ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b54e250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les phrases tokenis√©es sont : \n",
      " [['je', 'suis', 'tr√®s', 'content'], ['c√©tait', 'une', 'belle', 'journ√©e'], ['je', 'suis', 'd√©√ßu'], ['c√©tait', 'horrible'], ['jadore', 'ce', 'film'], ['je', 'd√©teste', 'ce', 'livre']]\n"
     ]
    }
   ],
   "source": [
    "def tokenize(sentence):\n",
    "    sentence = re.sub(r\"[^\\w\\s]\", \"\", sentence).lower() #pour supprimer ponctuation+miniscule\n",
    "    return sentence.split()\n",
    "\n",
    "tokenized_sentences = [tokenize(sent) for sent in phrases] # a chaque phrase\n",
    "print(\"Les phrases tokenis√©es sont : \\n\", tokenized_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0d628f",
   "metadata": {},
   "source": [
    "#### b. Vocabulaire contenant tous les mots distincts du corpus  <span id=\"vocabulaire\"></span>‚ÄÉ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le vocabulaire : ['d√©teste', 'je', 'ce', 'suis', 'belle', 'c√©tait', 'tr√®s', 'une', 'journ√©e', 'jadore', 'film', 'd√©√ßu', 'livre', 'horrible', 'content']\n"
     ]
    }
   ],
   "source": [
    "all_words = [word for sentence in tokenized_sentences for word in sentence] \n",
    "\n",
    "vocab = list(set(all_words))\n",
    "\n",
    "print(\"Le vocabulaire :\", vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c34316",
   "metadata": {},
   "source": [
    "#### c. Remplacement chaque mot par son indice dans ce vocabulaire <span id=\"remp\"></span>‚ÄÉ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c904a1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulaire : ['d√©teste', 'je', 'ce', 'suis', 'belle', 'c√©tait', 'tr√®s', 'une', 'journ√©e', 'jadore', 'film', 'd√©√ßu', 'livre', 'horrible', 'content']\n",
      "Dictionnaire mot ‚Üí indice : {'d√©teste': 0, 'je': 1, 'ce': 2, 'suis': 3, 'belle': 4, 'c√©tait': 5, 'tr√®s': 6, 'une': 7, 'journ√©e': 8, 'jadore': 9, 'film': 10, 'd√©√ßu': 11, 'livre': 12, 'horrible': 13, 'content': 14}\n"
     ]
    }
   ],
   "source": [
    "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "print(\"Vocabulaire :\", vocab)\n",
    "print(\"Dictionnaire :\", word_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e564da4",
   "metadata": {},
   "source": [
    "#### d. Raison d'ajout un jeton pad <span id=\"raison\"></span>‚ÄÉ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1e391f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulaire : ['<pad>', 'd√©teste', 'je', 'ce', 'suis', 'belle', 'c√©tait', 'tr√®s', 'une', 'journ√©e', 'jadore', 'film', 'd√©√ßu', 'livre', 'horrible', 'content']\n",
      "Dictionnaire mot ‚Üí indice : {'<pad>': 0, 'd√©teste': 1, 'je': 2, 'ce': 3, 'suis': 4, 'belle': 5, 'c√©tait': 6, 'tr√®s': 7, 'une': 8, 'journ√©e': 9, 'jadore': 10, 'film': 11, 'd√©√ßu': 12, 'livre': 13, 'horrible': 14, 'content': 15}\n"
     ]
    }
   ],
   "source": [
    "vocab = [\"<pad>\"] + list(set(all_words))\n",
    "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "\n",
    "print(\"Vocabulaire :\", vocab)\n",
    "print(\"Dictionnaire :\", word_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b69c902",
   "metadata": {},
   "source": [
    "‚ùì \n",
    "Le jeton 'pad' (pour \"padding \") est ajout√© au vocabulaire pour permettre le remplissage des s√©quences de mots , afin qu‚Äôelles aient toutes la m√™me longueur ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5a87d0",
   "metadata": {},
   "source": [
    "### üßÆ 5. Encodage <span id=\"encodage\"></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fa7811",
   "metadata": {},
   "source": [
    "#### a. Encodez chaque phrase sous forme de s√©quence d‚Äôindices <span id=\"encode\"></span>‚ÄÉ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84019cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrases Encodee :\n",
      " [[2, 4, 7, 15], [6, 8, 5, 9], [2, 4, 12], [6, 14], [10, 3, 11], [2, 1, 3, 13]]\n"
     ]
    }
   ],
   "source": [
    "encoded_sentences = []\n",
    "for sentence in tokenized_sentences:\n",
    "    encoded_sentence = [word_to_idx[word] for word in sentence if word in word_to_idx]\n",
    "    encoded_sentences.append(encoded_sentence)\n",
    "    \n",
    "\n",
    "#affichage\n",
    "print(\"Phrases Encodee :\\n\",encoded_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c2cc39",
   "metadata": {},
   "source": [
    "#### b. Padding sur les s√©quences <span id=\"padding\"></span>‚ÄÉ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ae2d3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrases apres padding :\n",
      " [[ 2  4  7 15]\n",
      " [ 6  8  5  9]\n",
      " [ 2  4 12  0]\n",
      " [ 6 14  0  0]\n",
      " [10  3 11  0]\n",
      " [ 2  1  3 13]]\n"
     ]
    }
   ],
   "source": [
    "max_length = max(len(seq) for seq in encoded_sentences)\n",
    "padded_sentences = pad_sequences(encoded_sentences, maxlen=max_length, padding='post', value=word_to_idx[\"<pad>\"])\n",
    "\n",
    "print(\"Phrases apres padding :\\n\", padded_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9363713e",
   "metadata": {},
   "source": [
    "### ü§ñ 6. Construction du mod√®le RNN <span id=\"modele\"></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab54abf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=10, hidden_dim=16):\n",
    "        super(SentimentLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0) #Une couche Embedding\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True) #Une couche RNN (LSTM)\n",
    "        self.fc = nn.Linear(hidden_dim, 1) #Une couche lin√©aire de sortie \n",
    "        self.sigmoid = nn.Sigmoid() #+ sigmo√Øde\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        out, (hidden, cell) = self.lstm(x) \n",
    "        out = self.fc(hidden[-1])\n",
    "        return self.sigmoid(out)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea17be0",
   "metadata": {},
   "source": [
    "### üöÄ 7. Entra√Ænement du mod√®le<span id=\"entrainement\"></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "246d7316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.7144\n",
      "Epoch 50, Loss: 0.0038\n",
      "Epoch 100, Loss: 0.0015\n",
      "Epoch 150, Loss: 0.0010\n",
      "Epoch 200, Loss: 0.0007\n",
      "Epoch 250, Loss: 0.0005\n",
      "Epoch 300, Loss: 0.0004\n",
      "Epoch 350, Loss: 0.0003\n",
      "Epoch 400, Loss: 0.0003\n",
      "Epoch 450, Loss: 0.0002\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.tensor(padded_sentences, dtype=torch.long)\n",
    "y_train = torch.tensor(labels, dtype=torch.float).view(-1, 1)\n",
    "\n",
    "model = SentimentLSTM(len(vocab))\n",
    "criterion = nn.BCELoss() #a) une fonction de perte adapt√©e √† la classification binaire.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Entra√Ænement\n",
    "for epoch in range(500): #b) Entra√Ænez le mod√®le sur plusieurs √©poques\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 50 == 0: \n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\") #c) Affichez l‚Äô√©volution de la perte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49a2bb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=10, hidden_dim=16):\n",
    "        super(SentimentGRU, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=word_to_idx[\"<pad>\"])\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        out, hidden = self.gru(x)\n",
    "        out = self.fc(hidden[-1])\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "# Initialisation du mod√®le\n",
    "model2 = SentimentGRU(vocab_size=len(vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "747305b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.0002\n",
      "Epoch 10, Loss: 0.0002\n",
      "Epoch 20, Loss: 0.0002\n",
      "Epoch 30, Loss: 0.0002\n",
      "Epoch 40, Loss: 0.0002\n",
      "Epoch 50, Loss: 0.0002\n",
      "Epoch 60, Loss: 0.0002\n",
      "Epoch 70, Loss: 0.0002\n",
      "Epoch 80, Loss: 0.0002\n",
      "Epoch 90, Loss: 0.0002\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100): \n",
    "    model2.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd223663",
   "metadata": {},
   "source": [
    "### üß™ 8. Pr√©diction <span id=\"prediction\"></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae328adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence): #a) Impl√©mentez une fonction predict(phrase) qui retourne :\n",
    "                        #\"Positif\" si le mod√®le pr√©dit une probabilit√© > 0.5\n",
    "                        #\"N√©gatif\" sinon\n",
    "    model.eval()\n",
    "    tokens = tokenize(sentence)\n",
    "    encoded = [word_to_idx.get(word, 0) for word in tokens]\n",
    "    padded = pad_sequences([encoded], maxlen=padded_sentences.shape[1], padding='post')\n",
    "    tensor_input = torch.tensor(padded, dtype=torch.long)\n",
    "    prob = model(tensor_input).item()\n",
    "    return \"Positif\" if prob > 0.5 else \"N√©gatif\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2585c3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√©gatif\n",
      "N√©gatif\n"
     ]
    }
   ],
   "source": [
    "#b) Test\n",
    "print(predict(\"je suis heureux\"))   \n",
    "print(predict(\"je suis triste\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fcaf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence): #par gru\n",
    "    model2.eval()\n",
    "    tokens = tokenize(sentence)\n",
    "    encoded = [word_to_idx.get(word, word_to_idx[\"<pad>\"]) for word in tokens]\n",
    "    padded = pad_sequences([encoded], maxlen=max_length, padding='post', value=word_to_idx[\"<pad>\"])\n",
    "    tensor_input = torch.tensor(padded, dtype=torch.long)\n",
    "    prob = model2(tensor_input).item()\n",
    "    print(f\"Probabilit√©: {prob:.4f}\")\n",
    "    return \"Positif\" if prob > 0.5 else \"N√©gatif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69fad92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilit√©: 0.4594\n",
      "N√©gatif\n",
      "Probabilit√©: 0.4594\n",
      "N√©gatif\n"
     ]
    }
   ],
   "source": [
    "print(predict(\"je suis heureux\"))\n",
    "print(predict(\"je suis triste\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5cdecd",
   "metadata": {},
   "source": [
    "### ‚ùì 9. R√©ponses aux questions du TP <span id=\"qst\"></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3a2267",
   "metadata": {},
   "source": [
    "##### 9.1. Pourquoi un RNN est-il utile ici, au lieu d‚Äôun r√©seau classique ?\n",
    "\n",
    "- Car le GRU prend en compte l‚Äôordre des mots dans une phrase, ce qui est essentiel pour bien detecter le sentiment ou bien le sens du phrase par contre un r√©seau classique ne prend pas en compte l‚Äôordre des mots.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9857c8",
   "metadata": {},
   "source": [
    "##### 9.2. Quels sont les inconv√©nients d‚Äôun RNN simple ?\n",
    "\n",
    "- Probl√®mes de gradient (disparition/exploration), et a du mal √† m√©moriser des informations importantes sur de longues s√©quences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc45dafa",
   "metadata": {},
   "source": [
    "##### 9.3. Que se passerait-il si on avait des phrases beaucoup plus longues ?\n",
    "\n",
    "- Un RNN simple aurait encore plus de mal, il faudrait utiliser LSTM ou Transformer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenvv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
